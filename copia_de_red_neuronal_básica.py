# -*- coding: utf-8 -*-
"""Copia de red_neuronal_básica.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HxR1HGZwHLstrc51NmskSTvWyu2wDGe8
"""

import numpy as np

"""# Implementación de la red neuronal con retropropagación"""

class NetNode(object):

  def __init__(self):
    self.inputs = []
    self.weights = []
    self.value = None

class Network(object):
  
  def __init__(self, layers, activation='relu'):
    self.net = [[NetNode() for _ in range(size)] for size in layers]
    self.activation = self.relu if activation == 'relu' else self.sigmoid
    self.activation_prime = self.relu_prime if activation == 'relu' else self.sigmoid_prime
    sizes = len(layers)
    for layer in range(1, sizes):
        for node in self.net[layer]:
            for unit in self.net[layer - 1]:
                node.inputs.append(unit)
                node.weights.append(0)

  def accuracy(self, examples):
    total_error = 0
    for x_test, y_test in examples:
        prediction = self.predict(x_test)
        total_error += np.sum(np.square(y_test - prediction))
    return total_error / len(examples)

  def backpropagation(self, learning_rate, training_data, epochs, activation_function="sigmoid"):
    nodes_values = []
    for epoch in range(epochs):
        random.shuffle(training_data)
        for x, y in training_data:
            self.layers[0].nodes = x
            for i in range(1, len(self.layers)):
                self.layers[i].calculate_output(self.layers[i - 1].nodes, activation_function)
            error = [y[j] - self.layers[-1].nodes[j] for j in range(len(y))]
            for i in range(len(self.layers) - 1, 0, -1):
                self.layers[i].backpropagate_error(self.layers[i - 1].nodes, error, self.layers[i - 1].weights, learning_rate, activation_function)
                error = self.layers[i].error
        nodes_values.append([x for x in self.layers[0].nodes])
        nodes_values.append([x for x in self.layers[-1].nodes])
    return nodes_values

  def predict(self, input_data):
    inputs = self.net[0]
    for v, n in zip(input_data, inputs):
        n.value = v
    for layer in self.net[1:]:
        for node in layer:
            in_val = [n.value for n in node.inputs]
            unit_value = np.dot(in_val, node.weights)
            if self.activation == 'relu':
                node.value = self.relu(unit_value)
            elif self.activation == 'sigmoide'
            
  def relu(self, z):
    return max(0, z)

  def relu_prime(self, z):
    return 1 if z > 0 else 0

  # agrega los métodos sigmoide() y sigmoide_prime() a la clase Network
  def sigmoide(self, z):
        return 1 / (1 + np.exp(-z))

  def sigmoide_prime(self, z):
      return self.sigmoide(z) * (1 - self.sigmoide(z))

  # agrega el método set_weights() a la clase Network, de tal forma que permite definir los pesos de las neuronas
  def set_weights(self, weights):
      for i, layer in enumerate(self.net):
          for j, node in enumerate(layer):
              node.weights = weights[i][j]

  # agrega el método weigths() a la clase Network, de tal forma que permita obtener los pesos de las neuronas
  def weights(self):
      weights_list = []
      for i, layer in enumerate(self.net):
          layer_weights = []
          for node in layer:
              layer_weights.append(node.weights)
          weights_list.append(layer_weights)
      return weights_list

"""# Usando la red neuronal con un dataset"""

from sklearn import datasets
from sklearn.preprocessing import normalize
from sklearn.model_selection import train_test_split
from keras.utils import np_utils

iris_X, iris_y = datasets.load_iris(return_X_y=True)

iris_x_normalized = normalize(iris_X, axis=0)

X_train, X_test, y_train, y_test = train_test_split(iris_x_normalized, iris_y, test_size=0.2, shuffle=True)

y_train = np_utils.to_categorical(y_train, num_classes=3)
y_test = np_utils.to_categorical(y_test, num_classes=3)

examples = []
for i in range(len(X_train)):
    examples.append([X_train[i], y_train[i]])

net = Network([4, 7, 3])
net.backpropagation(0.1, examples, 500)
weights_list = [[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24], [25, 26, 27, 28]],
                [[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7], [0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4], [1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1]]]
net.set_weights(weights_list)

#precisión alcanzada con los datos de entrenamiento
accuracy = net.accuracy(examples)
print(f"Accuracy: {accuracy}")

#precisión alcanzada con los datos de prueba
examples = []
for i in range(len(X_test)):
    examples.append([X_test[i], y_test[i]])
accuracy = net.accuracy(examples)
print(f"Accuracy: {accuracy}")

#probando con un dato
prediction = net.predict(X_test[2])
print(f"Desired output: {y_test[2]}")
print(f"Index of output: {prediction}")

"""# Modificación de la implementación de la red neuronal"""

# modifica la clase Network, para que se pueda decidir qué función de activación utilizar: relu() o sigmoide()

# los métodos predict() y accuracy() de la clase Network están implementados para resolver problemas de clasificación
# modifícalos de tal manera que también se puedan utilizar con problemas de regresión

# modifica el método backpropagation() de tal manera que devuelva como resultado el array de valores de los nodos durante las épocas de entrenamiento

# una vez implementados los cambios, entrena la red neuronal del ejemplo de los apuntes
examples = []
examples.append([[0.5, 0.67, 0.5], [0.25, 0.6]])

# ejecuta la red neuronal para los datos de ejemplo de los apuntes
# comprueba los valores de los nodos y de los pesos
# los valores de los nodos tienen que ser los mismos que los de los apuntes
# los valores de los pesos son ligeramente diferentes, ¿por qué?

net = Network([3, 4, 2])

net.set_weights([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])
# o
net.set_weights([[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [0.3, 0.3, 0.3], [0.4, 0.4, 0.4], [0.5, 0.5, 0.5, 0.5], [0.6, 0.6, 0.6, 0.6]])

valores_nodos = net.backpropagation(0.9, examples, 1)

print(valores_nodos)
net.weights()